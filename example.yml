inputs:
    - Kafka:
        codec: plain
        encoding: UTF8 # defaut UTF8
        topic: 
          app: 2
        consumer_settings:
          group.id: hangout
          zookeeper.connect: 192.168.1.200:2181
          auto.commit.interval.ms: "1000"
          socket.receive.buffer.bytes: "1048576"
          fetch.message.max.bytes: "1048576"
          num.consumer.fetchers: "4"
    - Kafka:
        codec: json
        topic: 
          web: 1
        consumer_settings:
          group.id: hangout
          zookeeper.connect: 192.168.1.201:2181
          auto.commit.interval.ms: "5000"

filters:
    - Grok:
        match:
          - '^(?<logtime>\S+) (?<user>.+) (-|(?<level>\w+)) %{DATA:msg}$'
        remove_fields: ['message']
    - Add:
        fields:
            test: 'abcd'
        if:
          - '<#if message??>true</#if>'
          - '<#if message?contains("liu")>true<#elseif message?contains("warn")>true</#if>'
    - Date:
        src: logtime
        formats:
            - 'ISO8601'
        remove_fields: ['logtime']
    - Lowercase:
        fields: ['user']
    - Add:
        fields:
          me: 'I am ${user}'
    - Remove:
        fields:
          - logtime
    - Trim:
        fields:
          - user
    - Rename:
        fields:
          me: he
          user: she
    - Gsub:
        fields:
          she: ['c','CCC']
          he: ['(^\w+)|(\w+$)','XXX']
    - Translate:
        source: user
        target: nick
        dictionary_path: /tmp/app.dic
    - KV:
        source: msg
        target: kv
        field_split: ' '
        value_split: '='
        trim: '\t\"'
        trimkey: '\"'
        include_keys: ["a","b","xyz","12"]
        exclude_keys: ["b","c"] # b in excluded
        tag_on_failure: "KVfail"
        remove_fields: ['msg']
    - Convert:
        fields:
            cs_bytes: 
                to: integer
                remove_if_fail: true # default false
            time_taken: 
                to: float
                setto_if_fail: 0.0 # default NOT set anything; should set remove_if_fail to false
    - URLDecode:
        fields: ["query1","query2"]
    - Json:
        filed: message # required
    - GeoIP2:
        source: message # required
        target: geoip # default geoip
        database: '/tmp/GeoLite2-City.mmdb'

outputs:
    - Stdout:
        if:
            - '<#if user=="childe">true</#if>'
    - Elasticsearch:
        cluster: hangoutcluster
        hosts:
          - 192.168.1.200
        index: 'hangout-%{user}-%{+YYYY.MM.dd}'
        index_type: logs # default logs
        bulk_actions: 20000 #default 20000
        bulk_size: 15 # default 15 MB
        flush_interval: 10 # default 10 seconds
        concurrent_requests: 0 # default 0, concurrent_requests设置成大于0的数, 意思着多线程处理, 以我应用的经验,还有是一定OOM风险的,强烈建议设置为0
        timezone: "Asia/Shanghai" # defaut UTC 时区. 只用于生成索引名字的字符串格式化
    - Kafka:
        broker_list: 192.168.1.200:9092
        topic: test2
